{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5503,"status":"ok","timestamp":1721122548022,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"},"user_tz":-120},"id":"AhbFCiyyjPjc","outputId":"73dc2f2b-4a03-4b3e-80b6-01552d950e64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary size (words): len(y[i]): 3358\n","Total X variables: 163552\n","\n","Text train example1\n"]},{"output_type":"display_data","data":{"text/plain":["'26003kt 9999 WM NSCNClD M 13 10 q1023 19004KT 9000 NSC 13/11 Q1023 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 1\n"]},{"output_type":"display_data","data":{"text/plain":["[436, 1, 2, 76, 3, 6, 12, 38, 210, 83, 74, 6, 10, 38, 4]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Text train example2\n"]},{"output_type":"display_data","data":{"text/plain":["'32005kt 9999 WM FEW030 SCT 15 11 q1013 34005KT 260V040 9999 FEW030 16/09 Q1014 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 2\n"]},{"output_type":"display_data","data":{"text/plain":["[270, 1, 2, 21, 31, 8, 10, 43, 199, 1129, 1, 21, 7, 15, 40, 4]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","X\n"]},{"output_type":"display_data","data":{"text/plain":["array([[   0,    0,    0,    0,    0,  436,    1,    2,   76,    3,    6,\n","          12,   38],\n","       [   0,    0,    0,    0,  436,    1,    2,   76,    3,    6,   12,\n","          38,  210],\n","       [   0,    0,    0,  436,    1,    2,   76,    3,    6,   12,   38,\n","         210,   83],\n","       [   0,    0,  436,    1,    2,   76,    3,    6,   12,   38,  210,\n","          83,   74],\n","       [   0,  436,    1,    2,   76,    3,    6,   12,   38,  210,   83,\n","          74,    6],\n","       [ 436,    1,    2,   76,    3,    6,   12,   38,  210,   83,   74,\n","           6,   10],\n","       [   1,    2,   76,    3,    6,   12,   38,  210,   83,   74,    6,\n","          10,   38],\n","       [   0,    0,    0,    0,    0,  270,    1,    2,   21,   31,    8,\n","          10,   43],\n","       [   0,    0,    0,    0,  270,    1,    2,   21,   31,    8,   10,\n","          43,  199],\n","       [   0,    0,    0,  270,    1,    2,   21,   31,    8,   10,   43,\n","         199, 1129],\n","       [   0,    0,  270,    1,    2,   21,   31,    8,   10,   43,  199,\n","        1129,    1],\n","       [   0,  270,    1,    2,   21,   31,    8,   10,   43,  199, 1129,\n","           1,   21],\n","       [ 270,    1,    2,   21,   31,    8,   10,   43,  199, 1129,    1,\n","          21,    7],\n","       [   1,    2,   21,   31,    8,   10,   43,  199, 1129,    1,   21,\n","           7,   15],\n","       [   2,   21,   31,    8,   10,   43,  199, 1129,    1,   21,    7,\n","          15,   40],\n","       [   0,    0,    0,    0,    0,  633,    1,   36,   76,    3,   10,\n","          10,   34],\n","       [   0,    0,    0,    0,  633,    1,   36,   76,    3,   10,   10,\n","          34,  230],\n","       [   0,    0,    0,  633,    1,   36,   76,    3,   10,   10,   34,\n","         230,  303],\n","       [   0,    0,  633,    1,   36,   76,    3,   10,   10,   34,  230,\n","         303,    1],\n","       [   0,  633,    1,   36,   76,    3,   10,   10,   34,  230,  303,\n","           1,  949],\n","       [ 633,    1,   36,   76,    3,   10,   10,   34,  230,  303,    1,\n","         949,   65],\n","       [   1,   36,   76,    3,   10,   10,   34,  230,  303,    1,  949,\n","          65,  160],\n","       [  36,   76,    3,   10,   10,   34,  230,  303,    1,  949,   65,\n","         160,   69],\n","       [  76,    3,   10,   10,   34,  230,  303,    1,  949,   65,  160,\n","          69,  881],\n","       [   3,   10,   10,   34,  230,  303,    1,  949,   65,  160,   69,\n","         881,   56]], dtype=int32)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Dictionary first 10 words\n"]},{"output_type":"display_data","data":{"text/plain":["{'9999': 1,\n"," 'wm': 2,\n"," 'm': 3,\n"," 'nosig': 4,\n"," '12': 5,\n"," '13': 6,\n"," '16': 7,\n"," '15': 8,\n"," '14': 9,\n"," '11': 10}"]},"metadata":{}}],"source":["#@title Get text train and test ,X and Y\n","nrows_train = 20000 # @param {type:\"integer\"}\n","sequence_length = 13 # @param {type:\"integer\"}\n","\n","feed_lenght = 8\n","\n","import pandas as pd\n","import numpy as np\n","import time\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import LSTM, Dense, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","import json\n","from keras.preprocessing.text import tokenizer_from_json\n","\n","#load fusion\n","fus = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/airport_ml/LECO/notebooks/LECOfusionml.csv\",\n","                  parse_dates=[\"time\"], index_col=\"time\")\n","\n","#Get the train and test train\n","texts_train = fus[\"fusion\"].sample(nrows_train,)\n","texts_test = fus[\"fusion\"].drop(texts_train.index)\n","\n","#save texts test\n","texts_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/airport_ml/LECO/notebooks/LECOtexts_testml.csv\")\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","\n","#tokenizer.fit_on_texts(texts_train)\n","tokenizer.fit_on_texts(fus[\"fusion\"])\n","\n","#Save tokenizer\n","tokenizer_json = tokenizer.to_json()\n","\n","# Save the JSON configuration to a file\n","with open('/content/drive/MyDrive/Colab Notebooks/airport_ml/LECO/algorithms/LECOtokenizerml.json', 'w', encoding='utf-8') as f:\n","    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n","\n","sequences = tokenizer.texts_to_sequences(texts_train)\n","\n","# Prepare input and output data\n","X = []\n","y = []\n","for sequence in sequences:\n","    for i in range(1, len(sequence)):\n","        x_seq = sequence[:i]\n","        x_seq_padded = pad_sequences([x_seq], maxlen=sequence_length, padding='pre')\n","        X.append(x_seq_padded[0])\n","        y.append(sequence[i])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","#filter seed/model words\n","df = pd.DataFrame(X)\n","df[\"y\"] = y\n","df_fil =  df[(df.iloc[:, :sequence_length-feed_lenght+1] != 0).any(axis=1)]\n","X = df_fil.iloc[:, :-1].values\n","y = df_fil.iloc[:, -1].values\n","\n","# One hot encode the outputs\n","y = np.eye(len(tokenizer.word_index) + 1)[y]\n","\n","print(\"Dictionary size (words): len(y[i]):\",len(y[1]) )\n","print(\"Total X variables:\",len(X) )\n","\n","print(\"\\nText train example1\")\n","display(texts_train[0])\n","\n","print(\"\\nSequences example 1\")\n","display(sequences[0])\n","\n","print(\"\\nText train example2\")\n","display(texts_train[1])\n","\n","print(\"\\nSequences example 2\")\n","display(sequences[1])\n","\n","print(\"\\nX\")\n","display(X[:25])\n","\n","print(\"\\nDictionary first 10 words\")\n","display({k: tokenizer.word_index[k] for k in list(tokenizer.word_index)[:10]})\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fOX-9Am0V_d","executionInfo":{"status":"ok","timestamp":1721124216491,"user_tz":-120,"elapsed":1477806,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"}},"outputId":"f04db193-2590-4d85-f1d6-1f87939afe86"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/70\n","320/320 [==============================] - 24s 65ms/step - loss: 3.8104 - accuracy: 0.2305\n","Epoch 2/70\n","320/320 [==============================] - 21s 64ms/step - loss: 2.7907 - accuracy: 0.3147\n","Epoch 3/70\n","320/320 [==============================] - 21s 65ms/step - loss: 2.4714 - accuracy: 0.3578\n","Epoch 4/70\n","320/320 [==============================] - 21s 66ms/step - loss: 2.2534 - accuracy: 0.3975\n","Epoch 5/70\n","320/320 [==============================] - 21s 64ms/step - loss: 2.1380 - accuracy: 0.4167\n","Epoch 6/70\n","320/320 [==============================] - 21s 65ms/step - loss: 2.0450 - accuracy: 0.4331\n","Epoch 7/70\n","320/320 [==============================] - 21s 64ms/step - loss: 1.9635 - accuracy: 0.4477\n","Epoch 8/70\n","320/320 [==============================] - 21s 66ms/step - loss: 1.8924 - accuracy: 0.4619\n","Epoch 9/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.8264 - accuracy: 0.4748\n","Epoch 10/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.7651 - accuracy: 0.4879\n","Epoch 11/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.7105 - accuracy: 0.4985\n","Epoch 12/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.6586 - accuracy: 0.5101\n","Epoch 13/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.6132 - accuracy: 0.5220\n","Epoch 14/70\n","320/320 [==============================] - 21s 66ms/step - loss: 1.5807 - accuracy: 0.5277\n","Epoch 15/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.5234 - accuracy: 0.5425\n","Epoch 16/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.4791 - accuracy: 0.5538\n","Epoch 17/70\n","320/320 [==============================] - 21s 64ms/step - loss: 1.4433 - accuracy: 0.5631\n","Epoch 18/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.4140 - accuracy: 0.5693\n","Epoch 19/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.3815 - accuracy: 0.5785\n","Epoch 20/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.3528 - accuracy: 0.5854\n","Epoch 21/70\n","320/320 [==============================] - 21s 64ms/step - loss: 1.3305 - accuracy: 0.5905\n","Epoch 22/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.3060 - accuracy: 0.5968\n","Epoch 23/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.2916 - accuracy: 0.5994\n","Epoch 24/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.2700 - accuracy: 0.6053\n","Epoch 25/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.2432 - accuracy: 0.6118\n","Epoch 26/70\n","320/320 [==============================] - 21s 64ms/step - loss: 1.2219 - accuracy: 0.6179\n","Epoch 27/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.2149 - accuracy: 0.6207\n","Epoch 28/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.2000 - accuracy: 0.6235\n","Epoch 29/70\n","320/320 [==============================] - 21s 66ms/step - loss: 1.1851 - accuracy: 0.6269\n","Epoch 30/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.1700 - accuracy: 0.6300\n","Epoch 31/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.1573 - accuracy: 0.6347\n","Epoch 32/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.1538 - accuracy: 0.6331\n","Epoch 33/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.1405 - accuracy: 0.6369\n","Epoch 34/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.1299 - accuracy: 0.6403\n","Epoch 35/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.1166 - accuracy: 0.6437\n","Epoch 36/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.1016 - accuracy: 0.6478\n","Epoch 37/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.1012 - accuracy: 0.6487\n","Epoch 38/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0988 - accuracy: 0.6474\n","Epoch 39/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0863 - accuracy: 0.6512\n","Epoch 40/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0827 - accuracy: 0.6531\n","Epoch 41/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0837 - accuracy: 0.6513\n","Epoch 42/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0616 - accuracy: 0.6575\n","Epoch 43/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0744 - accuracy: 0.6537\n","Epoch 44/70\n","320/320 [==============================] - 21s 66ms/step - loss: 1.0629 - accuracy: 0.6563\n","Epoch 45/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0662 - accuracy: 0.6549\n","Epoch 46/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0558 - accuracy: 0.6596\n","Epoch 47/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0508 - accuracy: 0.6576\n","Epoch 48/70\n","320/320 [==============================] - 21s 64ms/step - loss: 1.0534 - accuracy: 0.6578\n","Epoch 49/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0552 - accuracy: 0.6591\n","Epoch 50/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0519 - accuracy: 0.6581\n","Epoch 51/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0374 - accuracy: 0.6620\n","Epoch 52/70\n","320/320 [==============================] - 21s 64ms/step - loss: 1.0322 - accuracy: 0.6630\n","Epoch 53/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0446 - accuracy: 0.6587\n","Epoch 54/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0434 - accuracy: 0.6600\n","Epoch 55/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0250 - accuracy: 0.6658\n","Epoch 56/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0268 - accuracy: 0.6641\n","Epoch 57/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0431 - accuracy: 0.6593\n","Epoch 58/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0294 - accuracy: 0.6638\n","Epoch 59/70\n","320/320 [==============================] - 21s 66ms/step - loss: 1.0285 - accuracy: 0.6652\n","Epoch 60/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0260 - accuracy: 0.6630\n","Epoch 61/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0323 - accuracy: 0.6610\n","Epoch 62/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0296 - accuracy: 0.6631\n","Epoch 63/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0288 - accuracy: 0.6623\n","Epoch 64/70\n","320/320 [==============================] - 21s 64ms/step - loss: 1.0435 - accuracy: 0.6579\n","Epoch 65/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0403 - accuracy: 0.6590\n","Epoch 66/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0294 - accuracy: 0.6618\n","Epoch 67/70\n","320/320 [==============================] - 21s 65ms/step - loss: 0.9961 - accuracy: 0.6709\n","Epoch 68/70\n","320/320 [==============================] - 21s 64ms/step - loss: 1.0080 - accuracy: 0.6684\n","Epoch 69/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0276 - accuracy: 0.6641\n","Epoch 70/70\n","320/320 [==============================] - 21s 65ms/step - loss: 1.0599 - accuracy: 0.6537\n"]}],"source":["#@title Train the model\n","\n","from keras.layers import Bidirectional\n","\n","# Build the LSTM model\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=20, input_length=sequence_length),\n","    Bidirectional(LSTM(130)),\n","\n","    Dense(len(tokenizer.word_index)+1, activation='softmax')\n","])\n","\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=70,batch_size=512)\n","\n","#save the model\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/airport_ml/LECO/algorithms/LECOml.keras\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[{"file_id":"1PKiCntrB2pBLVWZRaL6x-uJpEvPlNmAg","timestamp":1717661221746},{"file_id":"1qsxpGdTrTbO4obEJ4QwGeDJUpuX7gXoW","timestamp":1717492644174},{"file_id":"1LGw-aME2JOnpzAyMOVamYWUAywgSV5mI","timestamp":1715852482288},{"file_id":"1_9maObId68xlnKd6JjYqJUMRMI14ASnx","timestamp":1715845357828},{"file_id":"1BterrhINI5z4G_D4Ntuk7p8a0iuZu7ql","timestamp":1714808806688},{"file_id":"1sqdm_O_jJnvjiOLxkCsuGODjv7CDiB0l","timestamp":1714549345450},{"file_id":"1GD83k4KMSFWH42Th2LjdPwK-hN39h8RT","timestamp":1713425984380}],"mount_file_id":"17ddfFgUgpP3PcmXYC2Hy16EWLbUUCIEG","authorship_tag":"ABX9TyMsXB6x0lWponeIVrs/iAUV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}