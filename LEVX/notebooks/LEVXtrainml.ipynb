{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6867,"status":"ok","timestamp":1721206593740,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"},"user_tz":-120},"id":"AhbFCiyyjPjc","outputId":"5eafd889-e7b6-40f5-f9a5-9fc4dbb717c7","cellView":"code"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary size (words): len(y[i]): 3033\n","Total X variables: 176733\n","\n","Text train example1\n"]},{"output_type":"display_data","data":{"text/plain":["'01013kt 9999 WM M040 M 26 16 q1015 01010KT 330V070 CAVOK 26/15 Q1014 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 1\n"]},{"output_type":"display_data","data":{"text/plain":["[253, 1, 3, 292, 4, 109, 10, 31, 684, 513, 5, 109, 12, 41, 2]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Text train example2\n"]},{"output_type":"display_data","data":{"text/plain":["'03003kt 9999 WM BKN005 M 17 14 q1020 00000KT CAVOK 16/15 Q1020 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 2\n"]},{"output_type":"display_data","data":{"text/plain":["[171, 1, 3, 78, 4, 17, 11, 30, 91, 5, 10, 12, 30, 2]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","X\n"]},{"output_type":"display_data","data":{"text/plain":["array([[   0,    0,    0,    0,    0,  253,    1,    3,  292,    4,  109,\n","          10,   31],\n","       [   0,    0,    0,    0,  253,    1,    3,  292,    4,  109,   10,\n","          31,  684],\n","       [   0,    0,    0,  253,    1,    3,  292,    4,  109,   10,   31,\n","         684,  513],\n","       [   0,    0,  253,    1,    3,  292,    4,  109,   10,   31,  684,\n","         513,    5],\n","       [   0,  253,    1,    3,  292,    4,  109,   10,   31,  684,  513,\n","           5,  109],\n","       [ 253,    1,    3,  292,    4,  109,   10,   31,  684,  513,    5,\n","         109,   12],\n","       [   1,    3,  292,    4,  109,   10,   31,  684,  513,    5,  109,\n","          12,   41],\n","       [   0,    0,    0,    0,    0,  171,    1,    3,   78,    4,   17,\n","          11,   30],\n","       [   0,    0,    0,    0,  171,    1,    3,   78,    4,   17,   11,\n","          30,   91],\n","       [   0,    0,    0,  171,    1,    3,   78,    4,   17,   11,   30,\n","          91,    5],\n","       [   0,    0,  171,    1,    3,   78,    4,   17,   11,   30,   91,\n","           5,   10],\n","       [   0,  171,    1,    3,   78,    4,   17,   11,   30,   91,    5,\n","          10,   12],\n","       [ 171,    1,    3,   78,    4,   17,   11,   30,   91,    5,   10,\n","          12,   30],\n","       [   0,    0,    0,    0,    0,  473,    1,    3,  145,   45,   34,\n","          97,  128],\n","       [   0,    0,    0,    0,  473,    1,    3,  145,   45,   34,   97,\n","         128,  259],\n","       [   0,    0,    0,  473,    1,    3,  145,   45,   34,   97,  128,\n","         259, 1150],\n","       [   0,    0,  473,    1,    3,  145,   45,   34,   97,  128,  259,\n","        1150,    1],\n","       [   0,  473,    1,    3,  145,   45,   34,   97,  128,  259, 1150,\n","           1,   80],\n","       [ 473,    1,    3,  145,   45,   34,   97,  128,  259, 1150,    1,\n","          80,   34],\n","       [   1,    3,  145,   45,   34,   97,  128,  259, 1150,    1,   80,\n","          34,   50],\n","       [   3,  145,   45,   34,   97,  128,  259, 1150,    1,   80,   34,\n","          50,   98],\n","       [   0,    0,    0,    0,    0,  121,    1,    3,   14,    4,   11,\n","          11,   30],\n","       [   0,    0,    0,    0,  121,    1,    3,   14,    4,   11,   11,\n","          30,   91],\n","       [   0,    0,    0,  121,    1,    3,   14,    4,   11,   11,   30,\n","          91,    1],\n","       [   0,    0,  121,    1,    3,   14,    4,   11,   11,   30,   91,\n","           1, 1124]], dtype=int32)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Dictionary first 10 words\n"]},{"output_type":"display_data","data":{"text/plain":["{'9999': 1,\n"," 'nosig': 2,\n"," 'wm': 3,\n"," 'm': 4,\n"," 'cavok': 5,\n"," '12': 6,\n"," '11': 7,\n"," '13': 8,\n"," '10': 9,\n"," '16': 10}"]},"metadata":{}}],"source":["#@title Get text train and test ,X and Y\n","nrows_train = 20000 # @param {type:\"integer\"}\n","sequence_length = 13 # @param {type:\"integer\"}\n","\n","feed_lenght = 8\n","\n","import pandas as pd\n","import numpy as np\n","import time\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import LSTM, Dense, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","import json\n","from keras.preprocessing.text import tokenizer_from_json\n","\n","#load fusion\n","fus = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/airport_ml/LEVX/notebooks/LEVXfusionml.csv\",\n","                  parse_dates=[\"time\"], index_col=\"time\")\n","\n","#Get the train and test train\n","texts_train = fus[\"fusion\"].sample(nrows_train,)\n","texts_test = fus[\"fusion\"].drop(texts_train.index)\n","\n","#save texts test\n","texts_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/airport_ml/LEVX/notebooks/LEVXtexts_testml.csv\")\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","\n","#tokenizer.fit_on_texts(texts_train)\n","tokenizer.fit_on_texts(fus[\"fusion\"])\n","\n","#Save tokenizer\n","tokenizer_json = tokenizer.to_json()\n","\n","# Save the JSON configuration to a file\n","with open('/content/drive/MyDrive/Colab Notebooks/airport_ml/LEVX/algorithms/LEVXtokenizerml.json', 'w', encoding='utf-8') as f:\n","    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n","\n","sequences = tokenizer.texts_to_sequences(texts_train)\n","\n","# Prepare input and output data\n","X = []\n","y = []\n","for sequence in sequences:\n","    for i in range(1, len(sequence)):\n","        x_seq = sequence[:i]\n","        x_seq_padded = pad_sequences([x_seq], maxlen=sequence_length, padding='pre')\n","        X.append(x_seq_padded[0])\n","        y.append(sequence[i])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","#filter seed/model words\n","df = pd.DataFrame(X)\n","df[\"y\"] = y\n","df_fil =  df[(df.iloc[:, :sequence_length-feed_lenght+1] != 0).any(axis=1)]\n","X = df_fil.iloc[:, :-1].values\n","y = df_fil.iloc[:, -1].values\n","\n","# One hot encode the outputs\n","y = np.eye(len(tokenizer.word_index) + 1)[y]\n","\n","print(\"Dictionary size (words): len(y[i]):\",len(y[1]) )\n","print(\"Total X variables:\",len(X) )\n","\n","print(\"\\nText train example1\")\n","display(texts_train[0])\n","\n","print(\"\\nSequences example 1\")\n","display(sequences[0])\n","\n","print(\"\\nText train example2\")\n","display(texts_train[1])\n","\n","print(\"\\nSequences example 2\")\n","display(sequences[1])\n","\n","print(\"\\nX\")\n","display(X[:25])\n","\n","print(\"\\nDictionary first 10 words\")\n","display({k: tokenizer.word_index[k] for k in list(tokenizer.word_index)[:10]})\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fOX-9Am0V_d","executionInfo":{"status":"ok","timestamp":1721208302157,"user_tz":-120,"elapsed":1653261,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"}},"outputId":"163c1c0e-e249-4d93-b751-d616e191d6f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/70\n","346/346 [==============================] - 27s 69ms/step - loss: 3.7490 - accuracy: 0.2339\n","Epoch 2/70\n","346/346 [==============================] - 24s 69ms/step - loss: 2.6668 - accuracy: 0.3287\n","Epoch 3/70\n","346/346 [==============================] - 23s 68ms/step - loss: 2.3835 - accuracy: 0.3710\n","Epoch 4/70\n","346/346 [==============================] - 24s 68ms/step - loss: 2.2300 - accuracy: 0.4012\n","Epoch 5/70\n","346/346 [==============================] - 24s 69ms/step - loss: 2.1426 - accuracy: 0.4178\n","Epoch 6/70\n","346/346 [==============================] - 23s 67ms/step - loss: 2.0747 - accuracy: 0.4286\n","Epoch 7/70\n","346/346 [==============================] - 23s 68ms/step - loss: 2.0161 - accuracy: 0.4372\n","Epoch 8/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.9566 - accuracy: 0.4477\n","Epoch 9/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.9029 - accuracy: 0.4565\n","Epoch 10/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.8425 - accuracy: 0.4682\n","Epoch 11/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.7928 - accuracy: 0.4786\n","Epoch 12/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.7393 - accuracy: 0.4888\n","Epoch 13/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.6911 - accuracy: 0.5010\n","Epoch 14/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.6452 - accuracy: 0.5106\n","Epoch 15/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.6022 - accuracy: 0.5207\n","Epoch 16/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.5624 - accuracy: 0.5301\n","Epoch 17/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.5226 - accuracy: 0.5379\n","Epoch 18/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.4890 - accuracy: 0.5489\n","Epoch 19/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.4658 - accuracy: 0.5532\n","Epoch 20/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.4348 - accuracy: 0.5607\n","Epoch 21/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.4059 - accuracy: 0.5676\n","Epoch 22/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.3786 - accuracy: 0.5750\n","Epoch 23/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.3583 - accuracy: 0.5809\n","Epoch 24/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.3425 - accuracy: 0.5835\n","Epoch 25/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.3244 - accuracy: 0.5878\n","Epoch 26/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.3052 - accuracy: 0.5939\n","Epoch 27/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.2876 - accuracy: 0.5977\n","Epoch 28/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.2771 - accuracy: 0.5979\n","Epoch 29/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.2625 - accuracy: 0.6028\n","Epoch 30/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.2494 - accuracy: 0.6060\n","Epoch 31/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.2368 - accuracy: 0.6099\n","Epoch 32/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.2372 - accuracy: 0.6081\n","Epoch 33/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.2305 - accuracy: 0.6091\n","Epoch 34/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.2154 - accuracy: 0.6146\n","Epoch 35/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.2111 - accuracy: 0.6146\n","Epoch 36/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1986 - accuracy: 0.6174\n","Epoch 37/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1836 - accuracy: 0.6217\n","Epoch 38/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1882 - accuracy: 0.6202\n","Epoch 39/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1934 - accuracy: 0.6198\n","Epoch 40/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1757 - accuracy: 0.6239\n","Epoch 41/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1710 - accuracy: 0.6245\n","Epoch 42/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.1683 - accuracy: 0.6246\n","Epoch 43/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1492 - accuracy: 0.6307\n","Epoch 44/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1550 - accuracy: 0.6280\n","Epoch 45/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1498 - accuracy: 0.6306\n","Epoch 46/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1699 - accuracy: 0.6250\n","Epoch 47/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1576 - accuracy: 0.6264\n","Epoch 48/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1385 - accuracy: 0.6323\n","Epoch 49/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1390 - accuracy: 0.6329\n","Epoch 50/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1488 - accuracy: 0.6305\n","Epoch 51/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1417 - accuracy: 0.6314\n","Epoch 52/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1393 - accuracy: 0.6310\n","Epoch 53/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1480 - accuracy: 0.6293\n","Epoch 54/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1611 - accuracy: 0.6256\n","Epoch 55/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.1803 - accuracy: 0.6207\n","Epoch 56/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.1713 - accuracy: 0.6220\n","Epoch 57/70\n","346/346 [==============================] - 24s 68ms/step - loss: 1.1442 - accuracy: 0.6292\n","Epoch 58/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1377 - accuracy: 0.6315\n","Epoch 59/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1276 - accuracy: 0.6341\n","Epoch 60/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1368 - accuracy: 0.6318\n","Epoch 61/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1354 - accuracy: 0.6309\n","Epoch 62/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1562 - accuracy: 0.6247\n","Epoch 63/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1469 - accuracy: 0.6269\n","Epoch 64/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1334 - accuracy: 0.6320\n","Epoch 65/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1584 - accuracy: 0.6258\n","Epoch 66/70\n","346/346 [==============================] - 23s 68ms/step - loss: 1.1652 - accuracy: 0.6224\n","Epoch 67/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1530 - accuracy: 0.6249\n","Epoch 68/70\n","346/346 [==============================] - 24s 69ms/step - loss: 1.1436 - accuracy: 0.6285\n","Epoch 69/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1249 - accuracy: 0.6334\n","Epoch 70/70\n","346/346 [==============================] - 23s 67ms/step - loss: 1.1228 - accuracy: 0.6347\n"]}],"source":["#@title Train the model\n","\n","from keras.layers import Bidirectional\n","\n","# Build the LSTM model\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=20, input_length=sequence_length),\n","    Bidirectional(LSTM(130)),\n","\n","    Dense(len(tokenizer.word_index)+1, activation='softmax')\n","])\n","\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=70,batch_size=512)\n","\n","#save the model\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/airport_ml/LEVX/algorithms/LEVXml.keras\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[{"file_id":"1PKiCntrB2pBLVWZRaL6x-uJpEvPlNmAg","timestamp":1717661221746},{"file_id":"1qsxpGdTrTbO4obEJ4QwGeDJUpuX7gXoW","timestamp":1717492644174},{"file_id":"1LGw-aME2JOnpzAyMOVamYWUAywgSV5mI","timestamp":1715852482288},{"file_id":"1_9maObId68xlnKd6JjYqJUMRMI14ASnx","timestamp":1715845357828},{"file_id":"1BterrhINI5z4G_D4Ntuk7p8a0iuZu7ql","timestamp":1714808806688},{"file_id":"1sqdm_O_jJnvjiOLxkCsuGODjv7CDiB0l","timestamp":1714549345450},{"file_id":"1GD83k4KMSFWH42Th2LjdPwK-hN39h8RT","timestamp":1713425984380}],"mount_file_id":"1RDxuCJRBWQQHZTShE9je3t4PnBneC4VJ","authorship_tag":"ABX9TyNq0s1LBx2JRhtSHrb+6rAX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}